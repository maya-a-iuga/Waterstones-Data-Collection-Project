{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper():\n",
    "\n",
    "    #use selenium to open desired webpage using Chrome\n",
    "    def __init__(self, url):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.url = url\n",
    "        self.page = self.driver.get(self.url)\n",
    "\n",
    "        #main book categories of the website\n",
    "        self.book_main_categories = []\n",
    "        self.category_subcategories = []\n",
    "        self.books_list_page = []\n",
    "        self.books_list_slider = []\n",
    "    \n",
    "    #bypass cookies\n",
    "    def bypass_cookies(self):\n",
    "    \n",
    "        # wait so website doesn't suspect you are a bot\n",
    "        time.sleep(2)\n",
    "\n",
    "        # if website has cookies\n",
    "        try:\n",
    "            accept_cookies_button = self.driver.find_element_by_xpath('//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "            accept_cookies_button.click()\n",
    "\n",
    "        # if website doesn't have cookies \n",
    "        except: \n",
    "            pass\n",
    "\n",
    "    # define flags for different conditions under which you can run the scraper\n",
    "    def scraper_flags(self):\n",
    "        # first flag is for choosing desired book category\n",
    "        self.category_parser = argparse.ArgumentParser(description = \"Which main book category you want to select?\")\n",
    "\n",
    "        ##for when runing .py file!!\n",
    "        # f for fiction\n",
    "        self.category_parser.add_argument('-f', action = \"store_true\")\n",
    "        # c for crime\n",
    "        self.category_parser.add_argument('-c', action = \"store_true\")\n",
    "        # sf for science-fiction\n",
    "        self.category_parser.add_argument('-sf', action = \"store_true\")\n",
    "        # g for graphic novels and manga\n",
    "        self.category_parser.add_argument('-g', action = \"store_true\")\n",
    "        # nf for non-fiction\n",
    "        self.category_parser.add_argument('-nf', action = \"store_true\")\n",
    "\n",
    "        ## for now in jupyter notebook use the below\n",
    "        #self.category_parser.add_argument(category_flag, action = \"store_true\")\n",
    "\n",
    "        self.category_args = self.category_parser.parse_args()\n",
    "\n",
    "    \n",
    "    #click/access one of the links\n",
    "    def access_book_category(self, item):\n",
    "        self.driver.get(item)  \n",
    "\n",
    "    #retrieves list of link with main books categories\n",
    "    def get_main_books_categories(self, desired_category):\n",
    "\n",
    "        #first part of xpath always navigated to desktop version of website desktop-navs\n",
    "        book_category_path = self.driver.find_element_by_xpath('//div[@class = \"navs-container desktop-navs\"]/ul[@class = \"subnavs\"][1]/li[2]')\n",
    "        # get all a elements containing the book categories\n",
    "        books_main_list = book_category_path.find_elements_by_xpath('.//span[@class = \"name nav-header-link\"]/a')\n",
    "        # we only interested in 5 categories: fiction, crime, science finction, graphic novel and non-fiction\n",
    "        # leaves out the children book categories\n",
    "        books_main_list = books_main_list[0:5]\n",
    "\n",
    "        # make this into a list compression \n",
    "        for item in books_main_list:\n",
    "            #a_tag = item.find_element_by_tag_name('a')\n",
    "            link = item.get_attribute('href')\n",
    "            self.book_main_categories.append(link)\n",
    "\n",
    "        #return book_main_categories\n",
    "        #based on passed category_flag, return desired link for next method\n",
    "        ## FOR WHEN RUNING .PY SCRIPT\n",
    "        #if self.category_args.fiction == True:\n",
    "         #   return self.book_main_categories[0]\n",
    "        #elif self.category_args.c == True:\n",
    "         #   return self.book_main_categories[1]\n",
    "        #elif self.category_args.sf == True:\n",
    "         #   return self.book_main_categories[2]\n",
    "        #elif self.category_args.g == True:\n",
    "         #   return self.book_main_categories[3]\n",
    "        #elif self.category_args.nf == True:\n",
    "         #   return self.book_main_categories[4]\n",
    "\n",
    "         ## JUST FOR NOW FOR IPYNB FILES\n",
    "        if desired_category == 'fiction':\n",
    "            return self.book_main_categories[0]\n",
    "        elif desired_category == 'crime':\n",
    "            return self.book_main_categories[1]\n",
    "        elif desired_category == 'science fiction':\n",
    "            return self.book_main_categories[2]\n",
    "        elif desired_category == 'graphic novel':\n",
    "            return self.book_main_categories[3]\n",
    "        elif desired_category == 'non fiction':\n",
    "            return self.book_main_categories[4]\n",
    "\n",
    "\n",
    "\n",
    "    #from main category - can now access all sub-categories buttons\n",
    "    def get_category_subcategories(self, desired_category):\n",
    "\n",
    "        self.category_subcategories = []\n",
    "        # calls function to retrieve desired book category and then loads corresponding page\n",
    "        category_header = self.get_main_books_categories(desired_category)\n",
    "        self.access_book_category(category_header)\n",
    "\n",
    "        #find list of category sub-divisions\n",
    "        subcategories_list = self.driver.find_elements_by_xpath('//div[@class = \"span3 tablet-span6 mobile-span6\"]//a')\n",
    "\n",
    "        for item in subcategories_list:\n",
    "            link = item.get_attribute('href')\n",
    "            self.category_subcategories.append(link)\n",
    "\n",
    "    \n",
    "    ## subcategory page: check if 'Our best <subcategory> exist if so you can scroll left/right and press\n",
    "    ## see all to display all the pages, otherwise skips this steps and directly goes to all pages display\n",
    "    \n",
    "    def finds_best_subcategory_list(self):\n",
    "\n",
    "        #for subcategory in self.category_subcategories :\n",
    "\n",
    "        # if header and see more button then press this - get data from full pages\n",
    "        \n",
    "        header_path = self.driver.find_element_by_xpath('//header[@class = \"span12 pages-header-row\"]')\n",
    "\n",
    "            #find see all button - sometimes called see more but same xpath\n",
    "        self.see_all_button = header_path.find_element_by_xpath('./a[@class = \"button button-teal\"]')\n",
    "        self.see_all_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        try:\n",
    "            header_path = self.driver.find_element_by_xpath('//header[@class = \"span12 pages-header-row\"]')\n",
    "            self.see_all_button = header_path.find_element_by_xpath('./a[@class = \"button button-teal\"]')\n",
    "            self.see_all_button.click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #self.get_book_list_page(3)\n",
    "        \n",
    "        #if you want instead to only get information from slider\n",
    "        #self.get_book_list_slider()\n",
    "                        \n",
    "        \n",
    "    ##GET FINAL BOOKS LIST\n",
    "    \n",
    "    #navigation method 1: get current url, scroll down, get next page url - FASTEST METHOD\n",
    "    #returns book list from see more pages\n",
    "    def get_book_list_page(self, pages_no):\n",
    "\n",
    "        if self.driver.current_url[-7 : -1] == \"?page=\":\n",
    "\n",
    "            self.current_url = self.driver.current_url[:-7] + '/page/'\n",
    "\n",
    "            i = 1\n",
    "            while i <= pages_no:\n",
    "\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                list_books_links = self.driver.find_elements_by_xpath('//div[@class = \"image-wrap\"]/a')\n",
    "                for item in list_books_links:\n",
    "                    link = item.get_attribute('href')\n",
    "                    self.books_list_page.append(link)\n",
    "\n",
    "                i += 1\n",
    "                self_new_current_url = ''\n",
    "                self.new_current_url = self.current_url + str(i)\n",
    "                self.driver.get(self.new_current_url) \n",
    "\n",
    "        \n",
    "        elif self.driver.current_url[-7 : -1] == \"/page/\":\n",
    "\n",
    "            self.current_url = self.driver.current_url[:-1]\n",
    "\n",
    "            i = 1\n",
    "            while i <= pages_no:\n",
    "\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                list_books_links = self.driver.find_elements_by_xpath('//div[@class = \"image-wrap\"]/a')\n",
    "                for item in list_books_links:\n",
    "                    link = item.get_attribute('href')\n",
    "                    self.books_list_page.append(link)\n",
    "\n",
    "                i += 1\n",
    "                self_new_current_url = ''\n",
    "                self.new_current_url = self.current_url + str(i)\n",
    "                self.driver.get(self.new_current_url)\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.current_url = self.driver.current_url + '/page/'\n",
    "            i = 1\n",
    "            while i <= pages_no:\n",
    "\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                list_books_links = self.driver.find_elements_by_xpath('//div[@class = \"image-wrap\"]/a')\n",
    "                for item in list_books_links:\n",
    "                    link = item.get_attribute('href')\n",
    "                    self.books_list_page.append(link)\n",
    "\n",
    "                i += 1\n",
    "                self_new_current_url = ''\n",
    "                self.new_current_url = self.current_url + str(i)\n",
    "                self.driver.get(self.new_current_url)\n",
    "\n",
    "\n",
    "    \n",
    "    ## loop through book links, access one at a time and then collect the meta-data from each book page\n",
    "    ## first method: enter book and navigate to click & collect information\n",
    "    # will need to adapt it to loop through all books\n",
    "    def click_and_collect(self, index):\n",
    "        self.access_book_category(self.all_links_next_page, index)\n",
    "\n",
    "        click_and_collect_button = self.driver.find_element_by_xpath('//div[@class = \"book-actions\"]//button[@class = \"button button-gold js-open-modal\"]')\n",
    "        click_and_collect_button.click()\n",
    "\n",
    "        search_bar = self.driver.find_element_by_xpath('//input[@placeholder = \"Town, city, or postcode\"]')\n",
    "        time.sleep(5)\n",
    "        search_bar.send_keys(\"WC1 0RW\")\n",
    "\n",
    "        go_button = self.driver.find_element_by_xpath('//button[@id = \"searchterm\"]')\n",
    "        go_button.click()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### also removes duplicate links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "         if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "             for x in flatten(item):\n",
    "                 yield x\n",
    "         else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if name == main run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    waterstones = Scraper(\"https://www.waterstones.com\")\n",
    "    waterstones.bypass_cookies()\n",
    "\n",
    "    list_categories = [\"fiction\", \"crime\", \"science fiction\", \"graphic novel\", \"non fiction\"]\n",
    "    final_book_list = []\n",
    "\n",
    "\n",
    "    for category in list_categories:\n",
    "\n",
    "        waterstones.get_category_subcategories(category)\n",
    "\n",
    "        for subcategory in waterstones.category_subcategories:\n",
    "\n",
    "            waterstones.access_book_category(subcategory)\n",
    "            waterstones.finds_best_subcategory_list()\n",
    "            waterstones.get_book_list_page(3)\n",
    "            final_book_list.append(waterstones.books_list_page)\n",
    "    \n",
    "    currated_list = list(flatten(final_book_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41472"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(flatten(final_book_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate Scraper object with desired url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterstones = Scraper(\"https://www.waterstones.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterstones.bypass_cookies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.waterstones.com/category/biography-true-stories',\n",
       " 'https://www.waterstones.com/category/food-drink',\n",
       " 'https://www.waterstones.com/category/history',\n",
       " 'https://www.waterstones.com/category/sports-leisure',\n",
       " 'https://www.waterstones.com/category/art-fashion-photography',\n",
       " 'https://www.waterstones.com/category/health-lifestyle',\n",
       " 'https://www.waterstones.com/category/popular-science-nature/popular-science',\n",
       " 'https://www.waterstones.com/category/travel-maps']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterstones.get_category_subcategories('non fiction')\n",
    "waterstones.category_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.waterstones.com/category/travel-maps'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waterstones.category_subcategories[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### navigation method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterstones.scroll_see_more_navigate(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### navigation method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterstones.scroll_down_up_next(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### navigation method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterstones.navigation_method_3(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra code from initial scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2578035342.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [117]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def navigation_method_1(self, pages_no):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "   #method 1: scroll down to end of page, wait, press load more and so on (number rep = number of pages scrolled)\n",
    "    #inside this method later will need to also get list of all links to the books -SECOND PLACE SPEED\n",
    "    def navigation_method_1(self, pages_no):\n",
    "\n",
    "        scroll_pause_time = 2\n",
    "        #gets current page height\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        #here using while true loop it go on forever - for now add counter to only load first 5 pages\n",
    "        #some problem with page number!! only loads until page 4 but no further?\n",
    "        i = 0\n",
    "        while i <= pages_no:\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(scroll_pause_time)\n",
    "\n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            if new_height == last_height:\n",
    "\n",
    "                all_books = self.driver.find_elements_by_xpath('//div[@class = \"image-wrap\"]/a')\n",
    "                for item in all_books:\n",
    "                    link = item.get_attribute('href')\n",
    "                    self.all_links_page.append(link)\n",
    "                show_more_button = self.driver.find_element_by_xpath('//button[@class = \"button button-teal\"]')\n",
    "                show_more_button.click()\n",
    "                break\n",
    "\n",
    "            #once at the bottom of page and see more pressed- reinitialises height\n",
    "            last_height = new_height\n",
    "            i +=1\n",
    "    \n",
    "    #method 2: scroll down, scroll back up and then press next arrow to navigate to next page -SLOWEST\n",
    "    def navigation_method_2(self, pages_no):\n",
    "\n",
    "        scroll_pause_time = 2\n",
    "\n",
    "        i = 1\n",
    "        while i <= pages_no:\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            all_books_this_page = self.driver.find_elements_by_xpath('//div[@class = \"image-wrap\"]/a')\n",
    "            for item in all_books_this_page:\n",
    "                link = item.get_attribute('href')\n",
    "                self.all_links_next_page.append(link)\n",
    "\n",
    "            #time.sleep(scroll_pause_time)\n",
    "\n",
    "            try:\n",
    "                go_back_up_button = self.driver.find_element_by_xpath('//div[@class = \"backtotop show stick\"]')\n",
    "                go_back_up_button.click()\n",
    "            except:\n",
    "                go_back_up_button = self.driver.find_element_by_xpath('//div[@class = \"backtotop show\"]')\n",
    "                go_back_up_button.click()\n",
    "\n",
    "            time.sleep(scroll_pause_time)\n",
    "\n",
    "            next_page = self.driver.find_element_by_xpath('//a[@title = \"Go to next page\"]')\n",
    "            next_page.click()\n",
    "            i += 1\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #alternatively can get directly a link to all existent sub-categories of all main categories\n",
    "    def get_all_subcategories(self):\n",
    "        all_subcategories = self.driver.find_elements_by_xpath('//div[@class = \"navs-container desktop-navs\"]//li[@class = \"subnav\"][2]//li[@class = \"subnav-item\"]')\n",
    "\n",
    "        for item in all_subcategories:\n",
    "            a_tag = item.find_element_by_tag_name('a')\n",
    "            link = a_tag.get_attribute('href')\n",
    "            self.all_subcategories.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    # method 2 returning book list from slider bar\n",
    "    def get_book_list_slider(self):\n",
    "\n",
    "        swiper_path = self.driver.find_element_by_xpath('//div[@class = \"swiper-wrapper\"]')\n",
    "        titles_path = swiper_path.find_elements_by_xpath('.//div[@class = \"title-wrap\"]')\n",
    "\n",
    "        for item in titles_path:\n",
    "            a_tag = item.find_element_by_tag_name('a')\n",
    "            link = a_tag.get_attribute('href')\n",
    "            self.books_list_slider.append(link)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "545e036c4b32438aced1f6b3c8d38ca151d9c36189e05839cb0aa568fda70ddd"
  },
  "kernelspec": {
   "display_name": "Python ('Data_Collection_Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
